{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Predictions for car battery life"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Problem overview:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This scenario focuses on predictions for car batteries reaching their rated number of cycles. The goal here is to avoid a sudden failure of the car battery and schedule it to be replaced before it reaches its rated number of cycles. The reduces significantly the risk of collateral failures occuring as well. From a business point of view, the target is optimize car battery replacement schedules to minimize overall maintenance costs. \n\nThe connected cars report on a daily basis information about the number of trips, duration of those trips and number of battery cycles used. Since reporting is performed on a daily basis, the battery age measured in days is also available as an input. The accumulated lifetime cycles used measure is also part of the dataset. As you can easily guess, the input data comes in the form of timeseries with the **Lifetime_Cycles_Used** field being the subject of prediction. Given the current timeseries for each battery, we are interested in forecasting the value of this field for the next 30 days to see whether the rated number of cycles will be exceeeded or not. \n\nThis scenario details the development of a machine learning time series forecasting model. The model is trained on a dataset containing battery telemetry information for 1539 days (between 1/1/2013 and 3/19/2017) for one car battery."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Solution overview:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will use the [Automated Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train) (autoML) capabilities of the [Azure Machine Learning service](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml) to quickly train a model that can forecast the evolution of the **Lifetime_Cycles_Used** metric. We will model our problem as a **Forecasting** problem where the goal of the trained model is to forecast the future evolution of a numerical indicator over a number of cycles (30 days in our case). The automML capabilities enable us to evaluate different algorithms and hyperparameters to get the best trained model for the problem with minimum effort. The approach used in this example cand be extended to various use cases that revolve around the need to predict the time series-based evolution of a numerical value.\n\n\nThis notebook is organized into the following sections:\n\n1. Basic setup\n\n2. Data prep\n\n3. Model training\n\n4. Explore the results and evaluate the best model\n\n5. Model Explainability: which features matter for the predictions?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Section 1. Basic setup\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Install the ```tqdm``` module which is required by forecasting model explainability."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade tqdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Import the necessary namespaces and classes."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nimport pandas as pd\nimport numpy as np\nimport logging\nimport warnings\n# Squash warning messages for cleaner output in the notebook\nwarnings.showwarning = lambda *args, **kwargs: None\n\nfrom matplotlib import pyplot as plt\n\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.experiment import Experiment\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.automlexplainer import explain_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Before starting this step, you need to create an Azure Machine Learning service workspace ([instructions](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-workspace)).\n\nLet's get started by creating an experiment in your Azure Machine Learning workspace. An experiment is a named object in a workspace, which is used to do model training."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "subscription_id = \"<subscription id goes here>\"\nresource_group = \"<resource group goes here>\"\nworkspace_name = \"<workspace name goes here>\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace(workspace_name = workspace_name,\n               subscription_id = subscription_id,\n               resource_group = resource_group)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# choose a name for the run history container in the workspace\nexperiment_name = 'CarBatteryLife'\n\n# project folder\nproject_folder = './sample_projects/automl-carbatterylifeforecast'\n\nexperiment=Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data = output, index = ['']).T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Section 2. Data prep\n\n```daily-battery-time-series.csv``` contains the data about the time-based evolution of the car battery parameters. It contains information for one battery during 1539 daily cycles (between 2013-01-01 and 2017-03-19)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.read_csv(\"https://quickstartsws9073123377.blob.core.windows.net/amlnotebooktutorials/customer-lifetime-value/daily-battery-time-series.csv\", parse_dates=['Date'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.1 Inspect data\n\nDisplay the first few rows of the data and view some plots to help you understand the dynamics within the dataset."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's take a look at some of the dataset properties."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(20,6))\n\nax1 = fig.add_subplot(211)\nax2 = fig.add_subplot(212)\nax1.plot(data['Daily_Trip_Duration'])\nax2.plot(data['Lifetime_Cycles_Used'])\nfig.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Since the dataset contains informatio for a single battery, we reduce the problem to forecasting the evolution of this single battery."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = data[['Date', 'Battery_Age_Days', 'Number_Of_Trips', 'Daily_Trip_Duration', 'Daily_Cycles_Used', 'Lifetime_Cycles_Used']]\ndata.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2 Split the data into train and test sets\n\nWhen working with timeseries, the approach used for split is to use the first X% occurences from the time series as training data and the remaining (100-X)% occurences as test data. Once the forecasting model is trained, it is used to make predictions for the occurrences from the test data. The differences between the predicted values and the actual values from the test data are used to measure the performance of the model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "time_column_name = 'Date'\ntarget_column_name = 'Lifetime_Cycles_Used'\n\nX_train = data[data[time_column_name] < '2016-04-15']\nX_test = data[data[time_column_name] >= '2016-04-15']\ny_train = X_train.pop(target_column_name).values\ny_test = X_test.pop(target_column_name).values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Section 3. Model training\n\nIn this section you will configure the [automated ML](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-automated-ml) feature of the Azure Machine Learning service. Using the configuration you will then run an automated ML experiment which explores various algorithms and hyperparameter values to generate machine learning models. Finally, the best model will be selected. The training jobs run on local compute resources (provided and managed by Azure Notebooks).\n\nThe significant advantage of automated ML is the acceleration of a data scientist's work (as it does a significant portion of the exploration work). Besides that, automated ML exposes rich data resulting from experiment runs which enables control, transparency, and, most importantly, visibility on what is happening behind the scenes.\n\nThe configuration data required by automated ML contains information about the experiment itself as well as the training data used to train the models. Below is an example of the most important components of the configuration data:\n\nProperty | Description\n--- | ---\ntask | regression\nprimary_metric | Metric that you want to optimize.<br>Forecasting supports the following primary metrics:<br>spearman_correlation<br>normalized_root_mean_squared_error<br>r2_score<br>normalized_mean_absolute_error\niterations | Number of iterations. In each individual iteration, automated ML trains one pipeline (algorithm and hyperparameters) on the given data.\niteration_timeout_minutes | The maximum number of minutes for each individual iteration\nX | Training data in the form [n_samples, n_features]\ny | Target values in the form [n_samples]\nn_cross_validations | Number of [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) splits.\npath | Relative path to the project folder. Automated ML stores configuration files for the experiment under this folder. You can specify a new empty folder.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.1 Automated ML configuration\n\nAutomated ML provides several options to configure the experiment runs, giving you flexibility and control. For example, the primary_metric setting specifies which metrich should automated ML use to optimize the machine learning model being built. There are multiple primary metrics available, and in our problem we will use NRMSE (Normalized Root Mean Squared Error).\n\nNotice that we've set the task to forecasting and we are also specifying the training data set (X_train and y_train). We need to do this because training is performed locally. When training in performed remotely (e.g. on AML compute resources) you will need to provide a script that contains code to get the data instead of the data itself.\n\nAlso, we are indicating the time column name and the maximum time horizon for the forecast (30 cycles which amount to 30 days in our case)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    \"time_column_name\": time_column_name, \n    \"max_horizon\": 30\n}\n\nautoml_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_carbatterylife_errors.log',\n                             primary_metric= 'normalized_root_mean_squared_error',\n                             iterations = 5,\n                             iteration_timeout_minutes = 5,\n                             X = X_train,\n                             y = y_train,\n                             n_cross_validations = 3,\n                             path=project_folder,\n                             verbosity = logging.INFO,\n                            **automl_settings)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.2 Train your models on local compute\n\nWhen you call the submit method on the experiment object and pass the AutoMLConfig object, automated ML will general a number of machine learning models equal to **iterations** (5 in our case). Depending on the input data and the number of iterations the time required to complete the traning can range from a few minutes to hours (or even mode). Once execution starts, you will see status messages being print out to the console."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.3 Monitor training"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To see the detailed results of the run, you can use a special widget (see the cell below).\n\n**Note**: When you want to start the run and continue to execute your code you need to specify ```show_output=False``` when calling ```experiment.submit()```."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(local_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Section 4. Explore the results and test the best model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.1 Retrieve all child runs\n\nEach individual model is trained in the context of a child run having **local_run** as its parent. You can get the list of all child runs and their logged metrics."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "children = list(local_run.get_children())\nmetricslist = {}\nfor run in children:\n    properties = run.get_properties()\n    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}    \n    metricslist[int(properties['iteration'])] = metrics\n\nrundata = pd.DataFrame(metricslist).sort_index(1)\nrundata",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.2 Retrieve the best fitted model\n\nThe **get_output** method enables you to retrieve the best child run and the associated fitted model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = local_run.get_output()\nfitted_model.steps",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.3 Test the best fitted model\n\nWe will now use the best model trained by automated ML to make predictions on the test data. Finally, the RMSE (Root Mean Squared Error) value will be calculated for the test data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred_test = fitted_model.predict(X_test)\ny_diff = np.abs(y_test - y_pred_test)\n\nrmse_test = ((y_test - y_pred_test) ** 2).mean() ** .5\nprint('RMSE for test data is {}'.format(rmse_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To get a visual representation of the result, let's display a couple of charts."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(30,15))\n\nax1 = fig.add_subplot(211)\nax1.plot(X_test['Date'], y_test, label='Actual')\nax1.plot(X_test['Date'], y_pred_test, label=\"Predicted\")\nax1.set_title('Actual battery life vs predicted for test data ')\nax1.legend()\nplt.xticks(rotation=90)\n\nax2 = fig.add_subplot(212)\nax2.plot(X_test['Date'], y_diff)\nax2.set_title('Difference between actual and predicted for test data ')\nplt.xticks(rotation=90)\n\nfig.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Section 5. Model Explainability: Which features matter for the predictions?\n\nNow that we have our trained model, we'd like to understand aspects related to its inner workings. One of the most important questions is \"Which feature matters the most in calculating the predictions?\".\n\nTo get the answer to the question, let's retrieve the explanation for our model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "shap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = explain_model(fitted_model, X_train, X_test, features=X_train.columns, best_run=best_run, y_train=y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "```overall_imp``` contains an ordered list of the features according to their importance. Notice that the list of features includes both features from the original dataset as well as features engineered by automated ML during the training process."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "overall_imp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}